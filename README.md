This study is completed as a 3rd year course project.


Bank text corpus is on /corpus/*

# Demo

# Our study

![alt text](https://github.com/nitrochange/finetuning-ruGPT3/blob/main/coursework.jpg)

[Google spreadsheet with GPT tests results](https://docs.google.com/spreadsheets/d/1qo_dyBgijADRM6W53eNLSP8sVqGLfyRgwHAxj4VGvdI/edit#gid=0)

[(colab) GPT-2 finetuning and generation with translator](https://colab.research.google.com/drive/1nhrtXwNU1vFsVPn25zf21CbqUkaU7sn6)

[(colab) ruGPT-3 finetuning and generation](https://colab.research.google.com/drive/13xPwb-UlYgblOeA8eFr_sK6MAOlPRNWi#scrollTo=5vL07XFvsBBU)

[(colab) bank corpus generation](https://colab.research.google.com/drive/1W3CNRWaOXCjv9l8XWqyVwOiW8wpgUz-u?usp=sharing)

[(colab) word2vec finetuning](https://colab.research.google.com/drive/1kDwHubiey3t5YeS0dymH1aB4ptwEvKB1#scrollTo=hlRjLHmlChSV)

[(colab) MultiBERT embeddings(with cosine distance)](https://colab.research.google.com/drive/1yJZdb-qZSqlf3waG3sKd-Bg9U3guTvZ2#scrollTo=B8wx1O_sTwl0)

[(colab) BigARTM(LDA)](https://colab.research.google.com/drive/1QCKMaCaqh5mV5I3Q0bFD9NwAjT3Vd6f-)

# Report

#Google doc to be placed here

# References

[Transformers and its applications (github)](https://github.com/huggingface/transformers)

[GPT-2 finetuning](https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce)

[ARAGPT2: Pre-Trained Transformer](https://arxiv.org/pdf/2012.15520.pdf)

[word2vec training](https://sysblok.ru/knowhow/obuchaem-word2vec-praktikum-po-sozdaniju-vektornyh-modelej-jazyka/)

[word2vec finetuning](https://www.kaggle.com/rtatman/fine-tuning-word2vec)

[НКРЯ - National corpus of the Russian language](https://ruscorpora.ru/new/)

[BERT overview](https://arxiv.org/pdf/2002.12327.pdf)

[BERT: Pre-training of Deep Bidirectional Transformers](https://arxiv.org/pdf/1810.04805.pdf)

[Distributed Representations of Words and Phrases
and their Compositionality](https://papers.nips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf)

[Training a natural language model with BERT and Tensorflow](https://habr.com/ru/company/sberdevices/blog/527576/)

[(colab) DeepPavlov: Transfer Learning with BERT](https://colab.research.google.com/github/deepmipt/dp_tutorials/blob/master/Tutorial_2_DeepPavlov_BERT_transfer_learning.ipynb)

[(colab) ruGPT-3 finetuning](https://colab.research.google.com/drive/1bwNxmVJMJ3x_N5ylS-nylkQpHUAF0DES)

[(colab) ruGPT-3 finetuning 2](https://colab.research.google.com/github/sberbank-ai/ru-gpts/blob/master/examples/Finetune_RuGPTs_with_HF.ipynb#scrollTo=aZ-4Kav28cH0)

# Authors

Alexander Romanov
Renat Nurtdinov

Advisor: Dmitry Ilvovsky

HSE FCS
